{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from google.cloud import vision\n",
    "import urllib.parse\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ratio = 55\n",
    "ratio *= 10\n",
    "\n",
    "product_name = \"shoe\"\n",
    "img_url = \"https://cdn.shopify.com/s/files/1/0468/9441/files/home_boots.jpg?v=1678983760&width=2000\"\n",
    "image_root_folder = \"sources\"\n",
    "clothes_type = \"Shoe\"\n",
    "os.makedirs(image_root_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(\"이미지 다운로드 완료\")\n",
    "    else:\n",
    "        print(\"이미지 다운로드 실패\")\n",
    "\n",
    "def localize_objects(path):\n",
    "    #출처: https://cloud.google.com/vision/docs/libraries?hl=ko\n",
    "    \"\"\"Localize objects in the local image.\n",
    "\n",
    "    Args:\n",
    "    path: The path to the local file.\n",
    "    \"\"\"\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    objects = client.object_localization(\n",
    "        image=image).localized_object_annotations\n",
    "    \n",
    "    print(f'Number of objects found: {len(objects)}')\n",
    "    for object_ in objects:\n",
    "        print(f'\\n{object_.name} (confidence: {object_.score})')\n",
    "        print('Normalized bounding polygon vertices: ')\n",
    "        for vertex in object_.bounding_poly.normalized_vertices:\n",
    "            print(f' - ({vertex.x}, {vertex.y})')\n",
    "            \n",
    "    return objects\n",
    "\n",
    "def find_smallest_rectangle(boxes):\n",
    "    min_x = float('inf')\n",
    "    min_y = float('inf')\n",
    "    max_x = float('-inf')\n",
    "    max_y = float('-inf')\n",
    "    \n",
    "    # 모든 상자의 좌표를 반복하여 최소 및 최대 좌표를 업데이트\n",
    "    for box in boxes:\n",
    "        left_top = box[0]  # 왼쪽 위 좌표\n",
    "        right_bottom = box[1]  # 오른쪽 아래 좌표\n",
    "        \n",
    "        min_x = min(min_x, left_top[0])\n",
    "        min_y = min(min_y, left_top[1])\n",
    "        max_x = max(max_x, right_bottom[0])\n",
    "        max_y = max(max_y, right_bottom[1])\n",
    "    \n",
    "    # 최소 및 최대 좌표를 사용하여 직사각형의 좌표를 구함\n",
    "    smallest_rectangle = [(min_x, min_y), (max_x, max_y)]\n",
    "    \n",
    "    return smallest_rectangle\n",
    "\n",
    "def resize_box(box, image_width, image_height, mul):\n",
    "    w = box[1][0] - box[0][0]\n",
    "    h = box[1][1] - box[0][1]\n",
    "\n",
    "    extended_x = (mul - 1) / 2 * w\n",
    "    extended_h = (mul - 1) / 2 * h\n",
    "\n",
    "    new_x1 = int(max(box[0][0] - extended_x, 0))\n",
    "    new_y1 = int(max(box[0][1] - extended_h, 0))\n",
    "    new_x2 = int(min(box[1][0] + extended_x, image_width))\n",
    "    new_y2 = int(min(box[1][1] + extended_h, image_height))\n",
    "    return [(new_x1, new_y1), (new_x2, new_y2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "parsed_url = urllib.parse.urlparse(img_url)\n",
    "file_name = os.path.basename(parsed_url.path)\n",
    "file_name = file_name.replace('/', '_')\n",
    "folder_path = image_root_folder + \"/\" + file_name\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "original_img = folder_path+\"/\"+\"original.jpg\"\n",
    "download_image(img_url, original_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드\n",
    "## 원본 이미지를 수정해서는 안됨.\n",
    "\n",
    "original = cv2.imread(original_img)\n",
    "original_height, original_width = original.shape[0], original.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마스크 생성\n",
    "#-------------------------------------------------\n",
    "# 모델 로드\n",
    "model = onnxruntime.InferenceSession('unet.onnx')\n",
    "\n",
    "mask = cv2.resize(original, (320, 320))\n",
    "\n",
    "mask = mask.transpose((2, 0, 1))  # 채널 순서 변경\n",
    "mask = mask.astype(np.float32) / 255.0  # 정규화\n",
    "mask = np.expand_dims(mask, axis=0)  # 배치 차원 추가\n",
    "\n",
    "# 모델 추론\n",
    "input_name = model.get_inputs()[0].name\n",
    "output_name = model.get_outputs()[0].name\n",
    "mask = model.run([output_name], {input_name: mask})[0]\n",
    "\n",
    "# 후처리\n",
    "mask = mask[0, 0, :, :]  # 배치와 채널 차원 제거\n",
    "mask = cv2.resize(mask, (original_width, original_height))  # 원래 크기로 복원. 이 마스크는 확장 영역을 선택할 때 쓰임.\n",
    "mask = (mask > 0.5).astype(np.uint8) * 255  # 이진화\n",
    "cv2.imwrite(folder_path+\"/\"+'mask.png', mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 0 1117 661\n"
     ]
    }
   ],
   "source": [
    "# 이미지 안의 사람의 크기 구함\n",
    "## 마스크 이용\n",
    "#-------------------------------------------------\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# 모든 객체의 윤곽선을 하나의 리스트로 병합\n",
    "all_contours = np.concatenate(contours)\n",
    "# 윤곽선을 감싸는 최소 사각형 좌표 계산\n",
    "object_x, object_y, object_w, object_h = cv2.boundingRect(all_contours)\n",
    "\n",
    "\n",
    "# 왼쪽 위를 기준으로 (x,y) 좌표, w(너비)와 h(높이) 형태로 결과 출력\n",
    "\n",
    "print(object_x, object_y, object_w, object_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 1261, 3) (730, 1261, 4)\n",
      "1117\n",
      "(730, 1261, 3) (359, 620, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아웃 페인팅하기 위해 1024*1024 이미지로 크기 조정\n",
    "## 사람의 크기 이용\n",
    "\n",
    "outpainting = cv2.cvtColor(original, cv2.COLOR_RGB2RGBA)\n",
    "print(original.shape, outpainting.shape)\n",
    "#객체의 긴 길이 구하기\n",
    "if object_w > object_h:\n",
    "    longer = object_w\n",
    "else:\n",
    "    longer = object_h\n",
    "print(longer)\n",
    "#인물의 객체의 긴 길이가 55%, 1024*1024에서 ratio픽셀을 차지하도록 설정\n",
    "new_width, new_height = int(outpainting.shape[1]*ratio/longer), int(outpainting.shape[0]*ratio/longer)\n",
    "outpainting = cv2.resize(outpainting, (new_width, new_height))\n",
    "print(original.shape, outpainting.shape)\n",
    "base_image = np.zeros((1024, 1024, 4), dtype=np.uint8)\n",
    "x_offset = int((base_image.shape[1] - outpainting.shape[1]) / 2)\n",
    "y_offset = int((base_image.shape[0] - outpainting.shape[0]) / 2)\n",
    "\n",
    "base_image[y_offset:y_offset + outpainting.shape[0], x_offset:x_offset + outpainting.shape[1]] = outpainting\n",
    "\n",
    "outpainting = base_image\n",
    "\n",
    "cv2.imwrite(folder_path+\"/\"+'outpainting.png', outpainting )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Dall-E로 아웃페인팅\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.organization = os.getenv(\"ORG_ID\")\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "outpainted = openai.Image.create_edit(\n",
    "  image=open(folder_path+\"/\"+\"outpainting.png\", \"rb\"),\n",
    "  prompt=\"photo of fashion model\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "image_url = outpainted.data[0]['url']\n",
    "\n",
    "response = requests.get(image_url)\n",
    "image_bytes = response.content\n",
    "\n",
    "\n",
    "download_image(image_url, folder_path+\"/\"+\"Dall_E2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 이미지 테두리를 반투명하게 처리\n",
    "feather = cv2.cvtColor(original, cv2.COLOR_BGR2BGRA)\n",
    "if original_height >= original_width:\n",
    "    border_size = int(0.05 * original_height)\n",
    "else: \n",
    "    border_size = int(0.05 * original_width)\n",
    "    \n",
    "for i in range(border_size):\n",
    "    feather[ i,:, 3] = int(255* i/border_size)\n",
    "    feather[-i,:, 3] = int(255* i/border_size)\n",
    "    feather[:, i, 3] = int(255* i/border_size)\n",
    "    feather[:,-i, 3] = int(255* i/border_size)\n",
    "\n",
    "\n",
    "feather[:border_size , :border_size, 3] = 0\n",
    "feather[:border_size , -border_size:, 3] = 0\n",
    "feather[-border_size:, -border_size:, 3] = 0\n",
    "feather[-border_size:, :border_size, 3] = 0\n",
    "\n",
    "for radius in range(0, border_size):\n",
    "    for angle in range(0, 90 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(original.shape[1]- border_size + radius * np.cos(radian))\n",
    "        y = int(original.shape[0]- border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "    for angle in range(90, 180 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(border_size + radius * np.cos(radian))\n",
    "        y = int(original.shape[0]- border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "    for angle in range(180, 270 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(border_size + radius * np.cos(radian))\n",
    "        y = int(border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255-255* radius/border_size)\n",
    "\n",
    "    for angle in range(270, 360 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(original.shape[1] - border_size + radius * np.cos(radian))\n",
    "        y = int(border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "cv2.imwrite(folder_path+\"/\"+'feather.png', feather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'composite', '-geometry', '+409+674', 'sources/home_boots.jpg/feather.png', 'sources/home_boots.jpg/alpha_compistion.png', 'sources/home_boots.jpg/alpha_compistion.png'], returncode=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아웃 페인팅 위에 기존 이미지 올리기\n",
    "## 반투명 처리된 이미지 이용\n",
    "\n",
    "result = cv2.imread(folder_path+\"/\"+'Dall_E2.png')\n",
    "new_length = int(1024*longer/ratio)\n",
    "result = cv2.resize(result, (new_length, new_length))\n",
    "\n",
    "cv2.imwrite(folder_path+\"/\"+\"alpha_compistion.png\", result)\n",
    "\n",
    "x_offset = int((new_length  - original_width) / 2)\n",
    "y_offset = int((new_length  - original_height) / 2)\n",
    "subprocess.run([\"./magick.appimage\",\"composite\", \"-geometry\", \"+\" + str(x_offset) + \"+\" +str(y_offset), folder_path+\"/\"+\"feather.png\", folder_path+\"/\"+\"alpha_compistion.png\", folder_path+\"/\"+\"alpha_compistion.png\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인체가 잘린 경계에서 확장된 부분 삭제\n",
    "os.rename(folder_path+\"/\"+\"alpha_compistion.png\", folder_path+\"/\"+\"result.png\")\n",
    "\n",
    "object_move_x = x_offset\n",
    "object_move_y = y_offset\n",
    "\n",
    "if object_x == 0:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", folder_path+\"/\"+\"result.png\", \"-gravity\", \"west\", \"-chop\", (str(x_offset)+\"x\"+\"0\"), folder_path+\"/\"+\"result.png\"])\n",
    "    object_move_x = 0\n",
    "if object_y == 0:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", folder_path+\"/\"+\"result.png\", \"-gravity\", \"north\", \"-chop\", (\"0\"+\"x\"+str(y_offset)), folder_path+\"/\"+\"result.png\"])\n",
    "    object_move_y = 0\n",
    "if object_x + object_w == original_width:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", folder_path+\"/\"+\"result.png\", \"-gravity\", \"east\", \"-chop\", (str(x_offset)+\"x\"+\"0\"), folder_path+\"/\"+\"result.png\"])\n",
    "if object_y + object_h == original_height:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", folder_path+\"/\"+\"result.png\", \"-gravity\", \"south\", \"-chop\", (\"0\"+\"x\"+str(y_offset)), folder_path+\"/\"+\"result.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects found: 3\n",
      "\n",
      "Shoe (confidence: 0.9475909471511841)\n",
      "Normalized bounding polygon vertices: \n",
      " - (0.06843020766973495, 0.29012230038642883)\n",
      " - (0.44998350739479065, 0.29012230038642883)\n",
      " - (0.44998350739479065, 0.8144310712814331)\n",
      " - (0.06843020766973495, 0.8144310712814331)\n",
      "\n",
      "Shoe (confidence: 0.9235299825668335)\n",
      "Normalized bounding polygon vertices: \n",
      " - (0.3926856517791748, 0.19473238289356232)\n",
      " - (0.9631771445274353, 0.19473238289356232)\n",
      " - (0.9631771445274353, 0.9090790748596191)\n",
      " - (0.3926856517791748, 0.9090790748596191)\n",
      "\n",
      "Pants (confidence: 0.6304260492324829)\n",
      "Normalized bounding polygon vertices: \n",
      " - (0.09170857071876526, 0.0)\n",
      " - (0.5339842438697815, 0.0)\n",
      " - (0.5339842438697815, 0.3711642026901245)\n",
      " - (0.09170857071876526, 0.3711642026901245)\n",
      "[mid: \"/m/06rrc\"\n",
      "name: \"Shoe\"\n",
      "score: 0.947590947\n",
      "bounding_poly {\n",
      "  normalized_vertices {\n",
      "    x: 0.0684302077\n",
      "    y: 0.2901223\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.449983507\n",
      "    y: 0.2901223\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.449983507\n",
      "    y: 0.814431071\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.0684302077\n",
      "    y: 0.814431071\n",
      "  }\n",
      "}\n",
      ", mid: \"/m/06rrc\"\n",
      "name: \"Shoe\"\n",
      "score: 0.92353\n",
      "bounding_poly {\n",
      "  normalized_vertices {\n",
      "    x: 0.392685652\n",
      "    y: 0.194732383\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.963177145\n",
      "    y: 0.194732383\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.963177145\n",
      "    y: 0.909079075\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.392685652\n",
      "    y: 0.909079075\n",
      "  }\n",
      "}\n",
      ", mid: \"/m/07mhn\"\n",
      "name: \"Pants\"\n",
      "score: 0.630426049\n",
      "bounding_poly {\n",
      "  normalized_vertices {\n",
      "    x: 0.0917085707\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.533984244\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.533984244\n",
      "    y: 0.371164203\n",
      "  }\n",
      "  normalized_vertices {\n",
      "    x: 0.0917085707\n",
      "    y: 0.371164203\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 확장된 영역의 크기에 따라 제공받은 Oject Detection 결과의 좌표를 이동\n",
    "\n",
    "objects = localize_objects(folder_path + \"/\" +\"original.jpg\")\n",
    "print(objects)\n",
    "for object_ in objects:\n",
    "    ###### 로직 작성해야하는 부분\n",
    "    if object_.name == clothes_type:\n",
    "        #####\n",
    "        break\n",
    "\n",
    "clothes_xy = object_.bounding_poly.normalized_vertices\n",
    "\n",
    "clothes_x = int(clothes_xy[0].x*original_width)\n",
    "clothes_y = int(clothes_xy[0].y*original_height)\n",
    "clothes_w = int(clothes_xy[2].x*original_width- clothes_xy[0].x*original_width)\n",
    "clothes_h = int(clothes_xy[2].y*original_height- clothes_xy[0].y*original_height)\n",
    "\n",
    "clothes_left_top = (clothes_x, clothes_y)\n",
    "clothes_right_bottom = (clothes_x + clothes_w, clothes_y + clothes_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shoe'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_\n",
    "clothes_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "resp = RetinaFace.detect_faces(folder_path+\"/\"+'original.jpg') #최초 실행시 모델 다운로드\n",
    "\n",
    "if \"face_1\" in resp:\n",
    "    face_location = resp[\"face_1\"][\"facial_area\"]\n",
    "    face_left_top = (face_location[0], face_location[1])\n",
    "    face_right_bottom = (face_location[2], face_location[3])\n",
    "    # face가 탐지된 경우에 대한 처리\n",
    "else:\n",
    "    # face가 탐지되지 않은 경우에 대한 처리\n",
    "    face_left_top = (clothes_x, clothes_y)\n",
    "    face_right_bottom = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#얼굴 영역에 바운딩 박스\n",
    "face_bounding_box = original.copy()\n",
    "cv2.rectangle(face_bounding_box, face_left_top, face_right_bottom, (0, 255, 0), 2)\n",
    "cv2.imwrite(folder_path+\"/\"+'face_bounding_box.jpg', face_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#옷 영역에 바운딩 박스\n",
    "clothes_bounding_box = original.copy()\n",
    "cv2.rectangle(clothes_bounding_box, clothes_left_top, clothes_right_bottom, (0, 255, 0), 2)\n",
    "cv2.imwrite(folder_path+\"/\"+'clothes_bounding_box.jpg', clothes_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#더 넓은 얼굴 영역 바운딩 박스와 두 박스를 포함하는 최소의 박스의 좌표를 구함.\n",
    "new_face_box_xy = resize_box([face_left_top, face_right_bottom], original_width, original_height, 1.8)\n",
    "boxes = [[clothes_left_top, clothes_right_bottom], new_face_box_xy]\n",
    "smallest_rectangle = find_smallest_rectangle(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_face_box = original.copy()\n",
    "cv2.rectangle(new_face_box, new_face_box_xy[0], new_face_box_xy[1], (0, 255, 0), 2)\n",
    "cv2.imwrite(folder_path+\"/\"+'new_face_box.jpg', new_face_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_bounding_box = original.copy()\n",
    "cv2.rectangle(smallest_bounding_box, smallest_rectangle[0], smallest_rectangle[1], (0, 255, 0), 2)\n",
    "cv2.imwrite(folder_path+\"/\"+'smallest_bounding_box.jpg', smallest_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "withClothes_xy = resize_box(smallest_rectangle, original_width, original_height, 1.1)\n",
    "onlyClothes_xy = resize_box([clothes_left_top, clothes_right_bottom], original_width, original_height, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 191), (591, 612)]\n",
      "[(61, 191), (591, 612)]\n"
     ]
    }
   ],
   "source": [
    "print(onlyClothes_xy)\n",
    "print(withClothes_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', '530x421+470+191', 'sources/home_boots.jpg/result_onlyClothes.png'], returncode=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", (str(onlyClothes_xy[1][0]-onlyClothes_xy[0][0]) + \"x\" + str(onlyClothes_xy[1][1]-onlyClothes_xy[0][1]) + \"+\" + str(onlyClothes_xy[0][0] + object_move_x) + \"+\" + str(onlyClothes_xy[0][1] + object_move_y)),\n",
    "     folder_path+\"/\"+\"result_onlyClothes.png\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', '530x421+470+191', 'sources/home_boots.jpg/result_withClothes.png'], returncode=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", (str(withClothes_xy[1][0]-withClothes_xy[0][0]) + \"x\" + str(withClothes_xy[1][1]-withClothes_xy[0][1]) + \"+\" + str(withClothes_xy[0][0] + object_move_x) + \"+\" + str(withClothes_xy[0][1] + object_move_y)),\n",
    "     folder_path+\"/\"+\"result_withClothes.png\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', 'x421+0+191', 'sources/home_boots.jpg/result_panorama_noFace.png'], returncode=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", (\"x\" + str(onlyClothes_xy[1][1]-onlyClothes_xy[0][1]) + \"+\" + str(0) + \"+\" + str(onlyClothes_xy[0][1] + object_move_y)),\n",
    "     folder_path+\"/\"+\"result_panorama_noFace.png\"]\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', 'x421+0+191', 'sources/home_boots.jpg/result_panorama_withFace.png'], returncode=0)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", (\"x\" + str(withClothes_xy[1][1]-withClothes_xy[0][1]) + \"+\" + str(0) + \"+\" + str(withClothes_xy[0][1] + object_move_y)),\n",
    "     folder_path+\"/\"+\"result_panorama_withFace.png\"]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', '530x+470+0', 'sources/home_boots.jpg/result_vertical_withFace.png'], returncode=0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", ((str(withClothes_xy[1][0]-withClothes_xy[0][0]) + \"x\") + \"+\" + str(withClothes_xy[0][0] + object_move_x) + \"+\" + str(0)),\n",
    "     folder_path+\"/\"+\"result_vertical_withFace.png\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['./magick.appimage', 'convert', 'sources/home_boots.jpg/result.png', '-crop', '530x+470+0', 'sources/home_boots.jpg/result_vertical_noFace.png'], returncode=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "    [\"./magick.appimage\",\n",
    "     \"convert\", folder_path+\"/\"+\"result.png\",\n",
    "     \"-crop\", ((str(onlyClothes_xy[1][0]-onlyClothes_xy[0][0]) + \"x\") + \"+\" + str(onlyClothes_xy[0][0] + object_move_x) + \"+\" + str(0)),\n",
    "     folder_path+\"/\"+\"result_vertical_noFace.png\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [Errno 111] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 6477869b12de238d683960a7, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m collection \u001b[39m=\u001b[39m db[\u001b[39m'\u001b[39m\u001b[39mclothesData\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: product_name,\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimage URL\u001b[39m\u001b[39m\"\u001b[39m: img_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mclothes_xy\u001b[39m\u001b[39m\"\u001b[39m: [clothes_left_top, clothes_right_bottom]\n\u001b[1;32m     13\u001b[0m     }\n\u001b[0;32m---> 14\u001b[0m collection\u001b[39m.\u001b[39;49minsert_one(data)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/collection.py:628\u001b[0m, in \u001b[0;36mCollection.insert_one\u001b[0;34m(self, document, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    624\u001b[0m     document[\u001b[39m\"\u001b[39m\u001b[39m_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ObjectId()  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    626\u001b[0m write_concern \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_concern_for(session)\n\u001b[1;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m InsertOneResult(\n\u001b[0;32m--> 628\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_insert_one(\n\u001b[1;32m    629\u001b[0m         document,\n\u001b[1;32m    630\u001b[0m         ordered\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    631\u001b[0m         write_concern\u001b[39m=\u001b[39;49mwrite_concern,\n\u001b[1;32m    632\u001b[0m         op_id\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    633\u001b[0m         bypass_doc_val\u001b[39m=\u001b[39;49mbypass_document_validation,\n\u001b[1;32m    634\u001b[0m         session\u001b[39m=\u001b[39;49msession,\n\u001b[1;32m    635\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[1;32m    636\u001b[0m     ),\n\u001b[1;32m    637\u001b[0m     write_concern\u001b[39m.\u001b[39macknowledged,\n\u001b[1;32m    638\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/collection.py:569\u001b[0m, in \u001b[0;36mCollection._insert_one\u001b[0;34m(self, doc, ordered, write_concern, op_id, bypass_doc_val, session, comment)\u001b[0m\n\u001b[1;32m    557\u001b[0m     result \u001b[39m=\u001b[39m sock_info\u001b[39m.\u001b[39mcommand(\n\u001b[1;32m    558\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__database\u001b[39m.\u001b[39mname,\n\u001b[1;32m    559\u001b[0m         command,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    564\u001b[0m         retryable_write\u001b[39m=\u001b[39mretryable_write,\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    567\u001b[0m     _check_write_command_response(result)\n\u001b[0;32m--> 569\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__database\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49m_retryable_write(acknowledged, _insert_command, session)\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(doc, RawBSONDocument):\n\u001b[1;32m    572\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_id\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/mongo_client.py:1475\u001b[0m, in \u001b[0;36mMongoClient._retryable_write\u001b[0;34m(self, retryable, func, session)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_retryable_write\u001b[39m(\u001b[39mself\u001b[39m, retryable, func, session):\n\u001b[1;32m   1474\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Internal retryable write helper.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1475\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tmp_session(session) \u001b[39mas\u001b[39;00m s:\n\u001b[1;32m   1476\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_with_session(retryable, func, s, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/mongo_client.py:1757\u001b[0m, in \u001b[0;36mMongoClient._tmp_session\u001b[0;34m(self, session, close)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[39myield\u001b[39;00m session\n\u001b[1;32m   1755\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_session(session)\n\u001b[1;32m   1758\u001b[0m \u001b[39mif\u001b[39;00m s:\n\u001b[1;32m   1759\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/mongo_client.py:1740\u001b[0m, in \u001b[0;36mMongoClient._ensure_session\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[39mreturn\u001b[39;00m session\n\u001b[1;32m   1737\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1738\u001b[0m     \u001b[39m# Don't make implicit sessions causally consistent. Applications\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m     \u001b[39m# should always opt-in.\u001b[39;00m\n\u001b[0;32m-> 1740\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__start_session(\u001b[39mTrue\u001b[39;49;00m, causal_consistency\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1741\u001b[0m \u001b[39mexcept\u001b[39;00m (ConfigurationError, InvalidOperation):\n\u001b[1;32m   1742\u001b[0m     \u001b[39m# Sessions not supported.\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/mongo_client.py:1685\u001b[0m, in \u001b[0;36mMongoClient.__start_session\u001b[0;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__start_session\u001b[39m(\u001b[39mself\u001b[39m, implicit, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1683\u001b[0m     \u001b[39m# Raises ConfigurationError if sessions are not supported.\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m implicit:\n\u001b[0;32m-> 1685\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_topology\u001b[39m.\u001b[39;49m_check_implicit_session_support()\n\u001b[1;32m   1686\u001b[0m         server_session \u001b[39m=\u001b[39m _EmptyServerSession()\n\u001b[1;32m   1687\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/topology.py:538\u001b[0m, in \u001b[0;36mTopology._check_implicit_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_implicit_session_support\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    537\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 538\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_session_support()\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/topology.py:554\u001b[0m, in \u001b[0;36mTopology._check_session_support\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_servers_loop(\n\u001b[1;32m    551\u001b[0m             any_server_selector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_server_selection_timeout(), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description\u001b[39m.\u001b[39mreadable_servers:\n\u001b[0;32m--> 554\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_select_servers_loop(\n\u001b[1;32m    555\u001b[0m         readable_server_selector, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_server_selection_timeout(), \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m session_timeout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description\u001b[39m.\u001b[39mlogical_session_timeout_minutes\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m session_timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/pymongo/topology.py:238\u001b[0m, in \u001b[0;36mTopology._select_servers_loop\u001b[0;34m(self, selector, timeout, address)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m server_descriptions:\n\u001b[1;32m    236\u001b[0m     \u001b[39m# No suitable servers.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m now \u001b[39m>\u001b[39m end_time:\n\u001b[0;32m--> 238\u001b[0m         \u001b[39mraise\u001b[39;00m ServerSelectionTimeoutError(\n\u001b[1;32m    239\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, Timeout: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39ms, Topology Description: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_message(selector), timeout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdescription)\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_opened()\n\u001b[1;32m    244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_check_all()\n",
      "\u001b[0;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [Errno 111] Connection refused, Timeout: 30s, Topology Description: <TopologyDescription id: 6477869b12de238d683960a7, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused')>]>"
     ]
    }
   ],
   "source": [
    "# 데이터 베이스에 객체(얼굴, 옷) 좌표 저장\n",
    "\n",
    "# MongoDB에 연결\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['fashionImageTest']\n",
    "collection = db['clothesData']\n",
    "data = {\n",
    "    \"name\": product_name,\n",
    "    \"image URL\": img_url,\n",
    "    \"file directory\": os.path.abspath(folder_path+\"/\"+\"result.png\"),\n",
    "    \"clothes type\": \"top\",\n",
    "    \"clothes_xy\": [clothes_left_top, clothes_right_bottom]\n",
    "    }\n",
    "collection.insert_one(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포토샵에 이미지 넣어서 배경 분리\n",
    "# 사람\n",
    "# 여백, 머리 포함(T/F), 배경색, 객체만(T/F), 비율 \n",
    "# 기본값(기본옵션) 설정해야함 -> 중요\n",
    "# 엑셀 파일로 json request 명세 작성\n",
    "# 클로즈업 https://tips.clip-studio.com/ko-kr/articles/4303#ee7cf6ea 옵션 고려\n",
    "# 시나리오를 먼저 생각하고 -> 옵션 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#의류타입이 상의인 경우, 상의가 이미지에서 2벌 이상 등장한다면 어떻게 처리할 것인가\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 경로 / 얼굴 위치 (별도 모델) / 사물 위치 / 상품 정보 1 / 상품 정보 2 / 상품 정보 3 / "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
