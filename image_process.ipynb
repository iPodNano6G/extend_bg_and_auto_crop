{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "ratio = 55\n",
    "ratio *= 10\n",
    "\n",
    "def download_image(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(\"이미지 다운로드 완료\")\n",
    "    else:\n",
    "        print(\"이미지 다운로드 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드\n",
    "## 원본 이미지를 수정해서는 안됨.\n",
    "\n",
    "image_path = \"남자.jpg\"\n",
    "original = cv2.imread(image_path)\n",
    "original_height, original_width = original.shape[0], original.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마스크 생성\n",
    "#-------------------------------------------------\n",
    "# 모델 로드\n",
    "model = onnxruntime.InferenceSession('unet.onnx')\n",
    "\n",
    "mask = cv2.resize(original, (320, 320))\n",
    "\n",
    "mask = mask.transpose((2, 0, 1))  # 채널 순서 변경\n",
    "mask = mask.astype(np.float32) / 255.0  # 정규화\n",
    "mask = np.expand_dims(mask, axis=0)  # 배치 차원 추가\n",
    "\n",
    "# 모델 추론\n",
    "input_name = model.get_inputs()[0].name\n",
    "output_name = model.get_outputs()[0].name\n",
    "mask = model.run([output_name], {input_name: mask})[0]\n",
    "\n",
    "# 후처리\n",
    "mask = mask[0, 0, :, :]  # 배치와 채널 차원 제거\n",
    "mask = cv2.resize(mask, (original_width, original_height))  # 원래 크기로 복원. 이 마스크는 확장 영역을 선택할 때 쓰임.\n",
    "mask = (mask > 0.5).astype(np.uint8) * 255  # 이진화\n",
    "cv2.imwrite('mask.png', mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 안의 사람의 크기 구함\n",
    "## 마스크 이용\n",
    "#-------------------------------------------------\n",
    "\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "all_contours = []\n",
    "for c in contours:\n",
    "    all_contours.extend(c)\n",
    "rect = cv2.minAreaRect(np.array(all_contours))\n",
    "box = cv2.boxPoints(rect)\n",
    "box = np.intp(box)\n",
    "\n",
    "# 왼쪽 위를 기준으로 (x,y) 좌표, w(너비)와 h(높이) 형태로 결과 출력\n",
    "\n",
    "object_x = box[0][0]\n",
    "object_y = box[0][1]\n",
    "object_w = box[2][0] - box[0][0] + 1\n",
    "object_h = box[2][1] - box[0][1] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아웃 페인팅하기 위해 1024*1024 이미지로 크기 조정\n",
    "## 사람의 크기 이용\n",
    "\n",
    "outpainting = cv2.cvtColor(original, cv2.COLOR_RGB2RGBA)\n",
    "\n",
    "#객체의 긴 길이 구하기\n",
    "if object_w > object_h:\n",
    "    longer = object_w\n",
    "else:\n",
    "    longer = object_h\n",
    "\n",
    "#인물의 객체의 긴 길이가 55%, 1024*1024에서 ratio픽셀을 차지하도록 설정\n",
    "new_width, new_height = int(outpainting.shape[1]*ratio/longer), int(outpainting.shape[0]*ratio/longer)\n",
    "outpainting = cv2.resize(outpainting, (new_width, new_height))\n",
    "\n",
    "base_image = np.zeros((1024, 1024, 4), dtype=np.uint8)\n",
    "x_offset = int((base_image.shape[1] - outpainting.shape[1]) / 2)\n",
    "y_offset = int((base_image.shape[0] - outpainting.shape[0]) / 2)\n",
    "\n",
    "base_image[y_offset:y_offset + outpainting.shape[0], x_offset:x_offset + outpainting.shape[1]] = outpainting\n",
    "\n",
    "outpainting = base_image\n",
    "\n",
    "cv2.imwrite('outpainting.png', outpainting )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Dall-E로 아웃페인팅\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "openai.organization = os.getenv(\"ORG_ID\")\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "outpainted = openai.Image.create_edit(\n",
    "  image=open(\"outpainting.png\", \"rb\"),\n",
    "  prompt=\"photo of fashion model\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-PRFs4kEWJsQsXXqKKPwiVGFn/user-3PmtWwSkpMcIRxBpjzwzXbZH/img-rg4qRFAuFJaqNSmML2eYwxxA.png?st=2023-05-15T05%3A10%3A06Z&se=2023-05-15T07%3A10%3A06Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-05-15T00%3A29%3A49Z&ske=2023-05-16T00%3A29%3A49Z&sks=b&skv=2021-08-06&sig=XQZruKh0rR8q1IxK84Hq2WN6QDiMq8DoSuA//MUjzew%3D\n"
     ]
    }
   ],
   "source": [
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m image_url \u001b[39m=\u001b[39m outpainted\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(image_url)\n\u001b[1;32m      4\u001b[0m image_bytes \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcontent\n\u001b[1;32m      6\u001b[0m file_path \u001b[39m=\u001b[39m image_path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_Dall-E2.png\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.conda/envs/autoImage/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_url = outpainted.data[0]['url']\n",
    "\n",
    "response = requests.get(image_url)\n",
    "image_bytes = response.content\n",
    "\n",
    "file_path = image_path+\"_Dall-E2.png\"\n",
    "\n",
    "download_image(image_url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 이미지 테두리를 반투명하게 처리\n",
    "feather = cv2.cvtColor(original, cv2.COLOR_BGR2BGRA)\n",
    "if original_height >= original_width:\n",
    "    border_size = int(0.05 * original_height)\n",
    "else: \n",
    "    border_size = int(0.05 * original_width)\n",
    "    \n",
    "for i in range(border_size):\n",
    "    feather[ i,:, 3] = int(255* i/border_size)\n",
    "    feather[-i,:, 3] = int(255* i/border_size)\n",
    "    feather[:, i, 3] = int(255* i/border_size)\n",
    "    feather[:,-i, 3] = int(255* i/border_size)\n",
    "\n",
    "\n",
    "feather[:border_size , :border_size, 3] = 0\n",
    "feather[:border_size , -border_size:, 3] = 0\n",
    "feather[-border_size:, -border_size:, 3] = 0\n",
    "feather[-border_size:, :border_size, 3] = 0\n",
    "\n",
    "for radius in range(0, border_size):\n",
    "    for angle in range(0, 90 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(original.shape[1]- border_size + radius * np.cos(radian))\n",
    "        y = int(original.shape[0]- border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "    for angle in range(90, 180 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(border_size + radius * np.cos(radian))\n",
    "        y = int(original.shape[0]- border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "    for angle in range(180, 270 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(border_size + radius * np.cos(radian))\n",
    "        y = int(border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255-255* radius/border_size)\n",
    "\n",
    "    for angle in range(270, 360 + 1):\n",
    "        radian = np.deg2rad(angle)\n",
    "        x = int(original.shape[1] - border_size + radius * np.cos(radian))\n",
    "        y = int(border_size + radius * np.sin(radian))\n",
    "        feather[y, x][3] = int(255 - 255* radius/border_size)\n",
    "\n",
    "cv2.imwrite('feather.png', feather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2390.271] global loadsave.cpp:244 findDecoder imread_('남자.jpg_Dall-E2.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(file_path)\n\u001b[1;32m      5\u001b[0m new_length \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1024\u001b[39m\u001b[39m*\u001b[39mlonger\u001b[39m/\u001b[39mratio)\n\u001b[0;32m----> 6\u001b[0m result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(result, (new_length, new_length))\n\u001b[1;32m      7\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(file_path, result)\n\u001b[1;32m      9\u001b[0m x_offset \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((new_length  \u001b[39m-\u001b[39m original_width) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# 아웃 페인팅 위에 기존 이미지 올리기\n",
    "## 반투명 처리된 이미지 이용\n",
    "\n",
    "result = cv2.imread(file_path)\n",
    "new_length = int(1024*longer/ratio)\n",
    "result = cv2.resize(result, (new_length, new_length))\n",
    "cv2.imwrite(file_path, result)\n",
    "\n",
    "x_offset = int((new_length  - original_width) / 2)\n",
    "y_offset = int((new_length  - original_height) / 2)\n",
    "print(x_offset, y_offset, original_width)\n",
    "subprocess.run([\"./magick.appimage\",\"composite\", \"-geometry\", \"+\" + str(x_offset) + \"+\" +str(y_offset), \"feather.png\", file_path, file_path])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인체가 잘린 경계에서 확장된 부분 삭제\n",
    "\n",
    "object_move_x = x_offset\n",
    "object_move_y = y_offset\n",
    "\n",
    "if object_x == 0:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", file_path, \"-gravity\", \"west\", \"-chop\", (str(x_offset)+\"x\"+\"0\"), file_path])\n",
    "    object_move_x = 0\n",
    "if object_y == 0:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", file_path, \"-gravity\", \"north\", \"-chop\", (\"0\"+\"x\"+str(y_offset)), file_path])\n",
    "    object_move_y = 0\n",
    "if object_x + object_w == original_width:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", file_path, \"-gravity\", \"east\", \"-chop\", (str(x_offset)+\"x\"+\"0\"), file_path])\n",
    "if object_y + object_h == original_height:\n",
    "    subprocess.run([\"./magick.appimage\",\"convert\", file_path, \"-gravity\", \"south\", \"-chop\", (\"0\"+\"x\"+str(y_offset)), file_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 310\n"
     ]
    }
   ],
   "source": [
    "# 확장된 영역의 크기에 따라 제공받은 Oject Detection 결과의 좌표를 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 베이스에 객체(얼굴, 옷) 좌표 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포토샵에 이미지 넣어서 배경 분리\n",
    "# 사람\n",
    "# 여백, 머리 포함(T/F), 배경색, 객체만(T/F), 비율,\n",
    "# 기본값(기본옵션) 설정해야함\n",
    "# 엑셀 파일로 json request 명세 작성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 경로 / 얼굴 위치 (별도 모델) / 사물 위치 / 상품 정보 1 / 상품 정보 2 / 상품 정보 3 / "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
